{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Process Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The natural languange process (NLP) consist in 6 tasks:\n",
    "1. Tokenization\n",
    "2. Stopword Removal\n",
    "3. N-Grams\n",
    "4. Word Sense Disambiguation\n",
    "5. Parts of Speech\n",
    "6. Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Tokenization: Breaking down a text into words and sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/Administrator/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Administrator/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/Administrator/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/Administrator/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mary had a little lamb.', 'Her fleece was white as snow']\n"
     ]
    }
   ],
   "source": [
    "text=\"Mary had a little lamb. Her fleece was white as snow\"\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "sents=sent_tokenize(text)\n",
    "print(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Mary', 'had', 'a', 'little', 'lamb', '.'], ['Her', 'fleece', 'was', 'white', 'as', 'snow']]\n"
     ]
    }
   ],
   "source": [
    "words=[word_tokenize(sent) for sent in sents]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. StopWord removal:\n",
    "Filter common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "customStopWords=set(stopwords.words('english')+list(punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mary', 'little', 'lamb', 'Her', 'fleece', 'white', 'snow']\n"
     ]
    }
   ],
   "source": [
    "wordsWOStopwords=[word for word in word_tokenize(text) if word not in customStopWords]\n",
    "print(wordsWOStopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.N-Grams (Bigrams): Identifying commonly occurring group of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Her', 'fleece'), 1),\n",
       " (('Mary', 'little'), 1),\n",
       " (('fleece', 'white'), 1),\n",
       " (('lamb', 'Her'), 1),\n",
       " (('little', 'lamb'), 1),\n",
       " (('white', 'snow'), 1)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.collocations import *\n",
    "bigram_measures=nltk.collocations.BigramAssocMeasures()\n",
    "finder=BigramCollocationFinder.from_words(wordsWOStopwords)\n",
    "sorted(finder.ngram_fd.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Word sense disambiguation: Identify the meaning of the word in the context where it occurs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('white.n.01') a member of the Caucasoid race\n",
      "Synset('white.n.02') the quality or state of the achromatic color of greatest lightness (bearing the least resemblance to black)\n",
      "Synset('white.n.03') United States jurist appointed chief justice of the United States Supreme Court in 1910 by President Taft; noted for his work on antitrust legislation (1845-1921)\n",
      "Synset('white.n.04') Australian writer (1912-1990)\n",
      "Synset('white.n.05') United States political journalist (1915-1986)\n",
      "Synset('white.n.06') United States architect (1853-1906)\n",
      "Synset('white.n.07') United States writer noted for his humorous essays (1899-1985)\n",
      "Synset('white.n.08') United States educator who in 1865 (with Ezra Cornell) founded Cornell University and served as its first president (1832-1918)\n",
      "Synset('white.n.09') a tributary of the Mississippi River that flows southeastward through northern Arkansas and southern Missouri\n",
      "Synset('egg_white.n.01') the white part of an egg; the nutritive and protective gelatinous substance surrounding the yolk consisting mainly of albumin dissolved in water\n",
      "Synset('white.n.11') (board games) the lighter pieces\n",
      "Synset('flannel.n.03') (usually in the plural) trousers made of flannel or gabardine or tweed or white cloth\n",
      "Synset('whiten.v.01') turn white\n",
      "Synset('white.a.01') being of the achromatic color of maximum lightness; having little or no hue owing to reflection of almost all incident light\n",
      "Synset('white.a.02') of or belonging to a racial group having light skin coloration\n",
      "Synset('white.s.03') free from moral blemish or impurity; unsullied\n",
      "Synset('white.s.04') marked by the presence of snow\n",
      "Synset('white.s.05') restricted to whites only\n",
      "Synset('white.s.06') glowing white with heat\n",
      "Synset('white.s.07') benevolent; without malicious intent\n",
      "Synset('blank.s.01') (of a surface) not written or printed on\n",
      "Synset('white.s.09') (of coffee) having cream or milk added\n",
      "Synset('white.s.10') (of hair) having lost its color\n",
      "Synset('ashen.s.01') anemic looking from illness or emotion; ; ; ; ; - Mary W. Shelley\n",
      "Synset('white.s.12') of summer nights in northern latitudes where the sun barely sets\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "for ss in wn.synsets('white'):\n",
    "    print(ss,ss.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('flannel.n.03') (usually in the plural) trousers made of flannel or gabardine or tweed or white cloth\n"
     ]
    }
   ],
   "source": [
    "from nltk.wsd import lesk\n",
    "sense1=lesk(word_tokenize(\"dressed in white\"),'white')\n",
    "print(sense1,sense1.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Part of Speech: Identify nouns, verbs and another parts of the text. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mary', 'NNP'),\n",
       " ('had', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('little', 'JJ'),\n",
       " ('lamb', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Her', 'PRP$'),\n",
       " ('fleece', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('white', 'JJ'),\n",
       " ('as', 'IN'),\n",
       " ('snow', 'NN')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Stemming: Removing end of the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mary', 'had', 'a', 'littl', 'lamb', '.', 'her', 'fleec', 'was', 'whit', 'as', 'snow']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "st=LancasterStemmer()\n",
    "stemmedWords=[st.stem(word) for word in word_tokenize(text)]\n",
    "print(stemmedWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mary', 'clos', 'on', 'clos', 'night', 'when', 'she', 'was', 'in', 'the', 'mood', 'to', 'clos', '.']\n"
     ]
    }
   ],
   "source": [
    "text2=\"Mary closed on closing night when she was in the mood to close.\"\n",
    "stemmedWords=[st.stem(word) for word in word_tokenize(text2)]\n",
    "print(stemmedWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
